# MoralTune: Fine-Tuning an LLM on r/AITA for Ethical Verdict Prediction  
CSS 488 – Natural Language Processing  
Option B: Fine-Tune a Model & Compare Performance

## Overview  
This project explores fine-tuning a large language model (LLM) on Reddit’s r/AmItheAsshole (r/AITA) dataset to classify moral verdicts. Given a user's post describing a social or ethical conflict, the model predicts whether the poster is "the asshole" or "not the asshole" based on community consensus.

We chose this task to gain hands-on experience with fine-tuning and classification using real-world, semi-structured data. r/AITA presents unique challenges due to its subjective, nuanced, and ethically rich content.

## Team Members  
6 roles


## Project Objectives  
- Fine-tune an open-source LLM (e.g., DistilBERT, GPT-2) on r/AITA posts  
- Build a binary classifier for “Asshole” vs “Not the Asshole” verdicts  
- Evaluate performance using accuracy, F1-score, and BERTScore (if generation is used)  
- Compare performance between the base and fine-tuned models  
- Discuss ethical implications and limitations of modeling moral judgment

## Dataset  
We used a subset of the r/AITA dataset scraped from Reddit using the PRAW API. Each sample contains:
- 


Note: We do not redistribute Reddit content in bulk. Small samples and derived features are included under fair use.

## Preprocessing  

## Model

## Evaluation  
- 

## Discussion  


## Future Work  
- 

## Requirements  
Install dependencies:
